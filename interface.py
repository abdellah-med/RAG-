import streamlit as st
from indexall_minilm import (
    connect_to_qdrant,
    create_collection,
    index_all_pdfs,
    get_similar_documents
)
from query_gen import generate_query
from agnooo import retrieve_and_ask
import pandas as pd

# Configuration de la page
st.set_page_config(
    page_title="Assistant IA - Conversations M√©dicales",
    page_icon="ü©∫",
    layout="wide"
)

# Application des styles CSS personnalis√©s
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #3366ff;
        text-align: center;
        margin-bottom: 2rem;
    }
    .subheader {
        font-size: 1.5rem;
        color: #0047ab;
        margin-top: 1.5rem;
        margin-bottom: 1rem;
        padding-left: 0.5rem;
        border-left: 4px solid #3366ff;
    }
    .doc-card {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 1rem;
        margin-bottom: 1rem;
        border-left: 4px solid #3366ff;
    }
    .recommendation-box {
        background-color: #eef5ff;
        border-radius: 10px;
        padding: 1.5rem;
        margin-top: 1rem;
        border: 1px solid #3366ff;
    }
    .sidebar-header {
        font-size: 1.2rem;
        font-weight: bold;
        margin-bottom: 1rem;
    }
    .footer {
        text-align: center;
        margin-top: 3rem;
        font-size: 0.8rem;
        color: #6c757d;
    }
    .stButton>button {
        background-color: #3366ff;
        color: white;
        border-radius: 5px;
        padding: 0.5rem 1rem;
        font-weight: bold;
    }
    .stButton>button:hover {
        background-color: #0047ab;
    }
</style>
""", unsafe_allow_html=True)

# Fonction pour afficher un spinner pendant le chargement
@st.cache_resource
def initialize_qdrant():
    # Initialisation de la connexion Qdrant
    collection_name = "corpus_a"
    client = connect_to_qdrant()
    should_index = create_collection(client, collection_name, 384)  # Taille des embeddings MiniLM-L6
    if should_index:
        with st.spinner("Indexation des documents PDF en cours..."):
            index_all_pdfs(client, collection_name, "ALLERG_IA")
    return client, collection_name

# Sidebar pour la configuration et les informations
with st.sidebar:
    st.markdown('<div class="sidebar-header">‚öôÔ∏è Configuration</div>', unsafe_allow_html=True)
    
    # Param√®tres de recherche
    st.subheader("Param√®tres")
    threshold = st.slider(
        "Seuil de pertinence (score minimum)",
        min_value=0.0,
        max_value=1.0,
        value=0.70,
        step=0.05,
        help="Les documents avec un score inf√©rieur √† ce seuil seront ignor√©s"
    )
    
    num_results = st.slider(
        "Nombre de r√©sultats √† afficher",
        min_value=1,
        max_value=10,
        value=5,
        help="Nombre maximum de documents similaires √† rechercher"
    )
    
    st.markdown("---")
    st.markdown("""
    <div style="font-size: 0.9rem">
    <b>√Ä propos</b><br>
    Cette application utilise l'IA pour analyser des conversations m√©dicales et sugg√©rer des questions pertinentes bas√©es sur une base documentaire.
    </div>
    """, unsafe_allow_html=True)

# Initialisation de Qdrant (avec cache pour √©viter la r√©indexation)
client, collection_name = initialize_qdrant()

# En-t√™te principal
st.markdown('<h1 class="main-header">ü©∫ Assistant IA pour Conversations M√©dicales</h1>', unsafe_allow_html=True)

# Tabs pour organiser l'interface
tab1, tab2 = st.tabs(["Analyse de Conversation", "Documentation"])

with tab1:
    # Champ de texte pour la conversation
    conversation_text = st.text_area(
        "Entrez la transcription de la conversation m√©dicale :",
        height=250,
        placeholder="Exemple: Le patient se plaint de d√©mangeaisons cutan√©es et de difficult√©s respiratoires apr√®s avoir consomm√© des fruits √† coque..."
    )
    
    # Boutons d'action
    col1, col2 = st.columns([1, 3])
    with col1:
        analyze_button = st.button("üîç Analyser la conversation", use_container_width=True)
    with col2:
        if st.button("üóëÔ∏è Effacer", use_container_width=True):
            conversation_text = ""
            st.experimental_rerun()
    
    # Analyse de la conversation
    if analyze_button:
        if conversation_text.strip():
            # Afficher un spinner pendant le traitement
            with st.spinner("Analyse en cours..."):
                # G√©n√©rer la query
                query = generate_query(conversation_text)
                
                # Cr√©er un conteneur pour afficher les r√©sultats
                results_container = st.container()
                
                with results_container:
                    st.markdown('<div class="subheader">üìä R√©sultats de l\'analyse</div>', unsafe_allow_html=True)
                    
                    # Afficher la requ√™te g√©n√©r√©e dans un expander
                    with st.expander("üîé Requ√™te g√©n√©r√©e"):
                        st.info(query)
                    
                    # R√©cup√©rer les documents similaires
                    top_docs = get_similar_documents(client, collection_name, query, num_results)
                    
                    # Filtrer les documents avec un score > seuil
                    filtered_docs = [doc for doc in top_docs if doc['score'] > threshold]
                    
                    # Affichage des documents r√©cup√©r√©s dans un tableau
                    if top_docs:
                        st.markdown('<div class="subheader">üìö Documents pertinents trouv√©s</div>', unsafe_allow_html=True)
                        
                        # Cr√©er un DataFrame pour afficher les r√©sultats de mani√®re plus organis√©e
                        docs_df = pd.DataFrame([
                            {
                                "Fichier": doc['file_name'],
                                "Score": f"{doc['score']:.2f}",
                                "Pertinent": "‚úÖ" if doc['score'] > threshold else "‚ùå"
                            } for doc in top_docs
                        ])
                        
                        st.dataframe(docs_df, use_container_width=True)
                        
                        # Afficher le contenu des documents dans des expanders
                        for i, doc in enumerate(top_docs):
                            with st.expander(f"Document {i+1}: {doc['file_name']} (Score: {doc['score']:.2f})"):
                                st.markdown(f"""
                                <div class="doc-card">
                                    <p><strong>Fichier:</strong> {doc['file_name']}</p>
                                    <p><strong>Chunk:</strong> {doc['chunk_number']}</p>
                                    <p><strong>Score:</strong> {doc['score']:.4f}</p>
                                    <hr>
                                    <p><strong>Contenu:</strong></p>
                                    <pre style="white-space: pre-wrap;">{doc['chunk_text']}</pre>
                                </div>
                                """, unsafe_allow_html=True)
                    else:
                        st.warning("‚ö†Ô∏è Aucun document similaire n'a √©t√© trouv√©.")
                    
                    # G√©n√©rer la r√©ponse
                    question = (
                        "Propose une seule question pertinente √† poser selon les informations et la discussion, "
                        "comme si elle √©tait pos√©e par le m√©decin. Explique √©galement quelles ressources (Documentation, Logigramme, etc.) "
                        "tu as utilis√©es pour choisir cette question."
                    )
                    
                    if not filtered_docs:
                        st.warning("‚ùå Aucun document ne d√©passe le seuil de pertinence minimum.")
                        response = retrieve_and_ask([{"chunk_text": "aucun document"}], question, conversation_text)
                    else:
                        response = retrieve_and_ask(filtered_docs, question, conversation_text)
                    
                    # Afficher la r√©ponse g√©n√©r√©e
                    st.markdown('<div class="subheader">üí° Suggestion de l\'IA</div>', unsafe_allow_html=True)
                    st.markdown(f'<div class="recommendation-box">{response}</div>', unsafe_allow_html=True)
        else:
            st.error("‚ö†Ô∏è Veuillez entrer une conversation avant d'analyser.")

with tab2:
    st.markdown('<div class="subheader">üìñ Documentation du syst√®me</div>', unsafe_allow_html=True)
    st.markdown("""
    ### Comment utiliser cette application

    1. **Entrez la transcription** de la conversation m√©decin-patient dans le champ de texte
    2. **Cliquez sur 'Analyser'** pour lancer le traitement
    3. **Consultez les r√©sultats** :
       - La requ√™te g√©n√©r√©e par l'IA
       - Les documents pertinents trouv√©s dans la base documentaire
       - La question recommand√©e par l'IA

    ### Fonctionnalit√©s principales

    - **Analyse de conversation** : extraction des informations cl√©s
    - **Recherche s√©mantique** : identification des documents pertinents
    - **IA g√©n√©rative** : suggestion de questions adapt√©es au contexte
    
    ### Base documentaire
    
    L'application utilise une base de connaissances sp√©cialis√©e en allergologie stock√©e dans la collection "corpus_a".
    """)

# Pied de page
st.markdown("""
<div class="footer">
    ¬© 2025 - Assistant IA pour Conversations M√©dicales - D√©velopp√© avec Streamlit
</div>
""", unsafe_allow_html=True)